---
title: "checkin' out data"
output: html_document
date: "2023-02-21"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

stuff for doing stuff
```{r}
library(tidyverse)
library(janitor)
library(here)
library(naniar)
library(ggplot2)
```

yassifying

```{r}
install.packages("RColorBrewer")
install.packages("paletteer")
install.packages("ggthemes")
install.packages("extrafont")
```
```{r}
library(RColorBrewer)
library(paletteer)
library(ggthemes)
library(extrafont)
```

```{r}
#setwd("emlieu_breakfast_price")
#setwd("/Users/eclieu/Desktop/emlieu_breakfast_price")

#setwd("/Users/eclieu/Desktop/BIS15W2023_elieu/")
#setwd("/Users/eclieu/Desktop/emlieu_breakfast_price/")
```
```{r}
#getwd()
```


## Looking at The Data
```{r}
avo <- read_csv("avocado-updated-2020 2.csv")
```

```{r}
avo
```
## Note from Data: 
4046: refers to non orgo small/med hass avos
4225: refers to non orgo large hass avos (8-10 oz)
4770: refers to non orgo extra large avos (10-15 oz)

## What are we trying to get from this data? Why do we care?
# Main Premise: 
tim and i want to continue eating avo toast for brekkie, but cost is going up. So where can we move to in order to live out our avo dreams until we are too broke?

#Things to Consider/ Think About:
organic or non organic(conventional)?
finding the trend/ slope of how much avos are increasing every year in particular locations (where we live now, where the data says the cheapest avos are, where avos are the most expensive bc why not) (plot?)
lets put it on a map why not (map?)
assuming we keep our current wages, what year do we have to time travel to in order to max out our avo consumption (most cheap, calculate slope first)
as opoosed to avos in general (above), let's get specific:
what size do people in particular locations prefer?
do people on average prefer organic or conventional? does this differ by location? (map?)


#Generic guidelines
1 app?, couple plots
5 mins presentation
be happy

## Data Analysis 
```{r}
org_avo <- avo %>% 
  filter (type == "organic") %>% 
  arrange(desc(average_price))
org_avo
```
```{r}
pleb_avo <- avo %>% 
  filter(type == "conventional") %>% 
  arrange(desc(average_price))
pleb_avo
```
```{r}
avo %>% 
  select("year", "geography", "average_price", "type") %>% 
  arrange(desc(average_price))
```
```{r}
avo %>% 
  select("year", "geography", "average_price", "type") %>% 
  arrange(average_price)
```

## Notice: 
the cheapest avos are not necessarily in the oldest year, they are probably where people don't usually eat avos 

```{r}
pleb_avo %>% 
  select("year", "geography", "average_price") %>% 
  arrange(desc(average_price))
```
```{r}
pleb_avo %>% 
  select("year", "geography", "average_price") %>% 
  arrange(average_price)
```
```{r}
org_avo %>% 
  select("year", "geography", "average_price") %>% 
  arrange(desc(average_price))
```
```{r}
org_avo %>% 
  select("year", "geography", "average_price") %>% 
  arrange(average_price)
```

#Note:
for non orgo avos, the most expensive are in chicago for $2.22 and the cheapest are in phoenix/tucson for .46c. I also notice that these max and min prices are both in 2017, along with the cheapest avos overall. However the most expensive were in 2016. I also think it's interesting how the cheapest avos overall were actually organic and not conventional. 

#Plan
locations of interest:
sf (most expensive overall/ for org)
chicago (most expensive for pleb)
Cincinnati/Dayton (cheapest overall/ for org)
pheonix/tucson (cheapest for pleb)
sacramento (where we are to compare)
```{r}
font_import()
loadfonts(device = "win")
```
```{r}
grDevices::colors()
```

```{r}
avo$year <- as.factor(avo$year)
avo
```
```{r}
sf_data <- avo %>% 
  filter(geography == "San Francisco")
sf_data
```
```{r}
sf_data <- sf_data %>%
    mutate(time_dif = as.double(difftime(date, lubridate::ymd("2015-01-04")), units= "days"))
sf_data
```

```{r}
sf_data %>% 
  ggplot(aes(x= date, y= average_price))+
  geom_point()+
  stat_smooth(method= lm, se= F)
```

```{r}
options(scipen= 999)
```

```{r}
ggplotRegression <- function(fit){
ggplot(fit$model, aes_string(x = names(fit$model)[2], y = names(fit$model)[1])) + 
  geom_point() +
  stat_smooth(method = "lm", col = "red") +
  labs(title = paste("Intercept =",signif(fit$coef[[1]],5 ),
                     " Slope =",signif(fit$coef[[2]], 5)))


  }

ggplotRegression(lm(average_price ~ time_dif, data = sf_data))

```

#final sf graph
```{r}
sf_data %>% 
ggplot(aes(x= date, y= average_price))+
geom_point(color= "palegreen4")+
geom_smooth(method= lm, se= F, color= "burlywood4")+
labs(title = "Sf Price Per Avo; Intercept =1.7728, Slope = -0.000012", 
     x= "Date",
     y= "Average Price")+
  theme(text=element_text(size=13, family="Comic Sans MS"),
            axis.text.x = element_text(angle = 60, hjust=1))
```

```{r}
chic_data <- avo %>% 
  filter(geography == "Chicago") %>% 
  mutate(time_dif = as.double(difftime(date, lubridate::ymd("2015-01-04")), units= "days"))
chic_data
```
```{r}
ggplotRegression(lm(average_price ~ time_dif, data = chic_data))

```

#final chocago graph
```{r}
chic_data %>% 
  ggplot(aes(x= date, y= average_price))+
 geom_point(color= "palegreen4")+
geom_smooth(method= lm, se= F, color= "burlywood4")+
  labs(title = "Chicago Price Per Avo; Intercept = 1.5219, Slope = 0.000002", 
     x= "Date",
     y= "Average Price")+
  theme(text=element_text(size=11, family="Comic Sans MS"),
            axis.text.x = element_text(angle = 60, hjust=1))
```

```{r}
cinday_data <- avo %>% 
  filter(geography == "Cincinnati/Dayton") %>% 
  mutate(time_dif = as.double(difftime(date, lubridate::ymd("2015-01-04")), units= "days"))
cinday_data
```

```{r}
ggplotRegression(lm(average_price ~ time_dif, data = cinday_data))
```

#final cincinnati/dayton graph
```{r}
cinday_data %>%  
  ggplot(aes(x= date, y= average_price))+
   geom_point(color= "palegreen4")+
geom_smooth(method= lm, se= F, color= "burlywood4")+
  labs(title = "Cincinnati/Dayton Price Per Avo; Intercept = 1.1692, Slope = 0.000064", 
     x= "Date",
     y= "Average Price")+
  theme(text=element_text(size=11, family="Comic Sans MS"),
            axis.text.x = element_text(angle = 60, hjust=1))
```

```{r}
photuc_data <- avo %>% 
  filter(geography == "Phoenix/Tucson") %>% 
  mutate(time_dif = as.double(difftime(date, lubridate::ymd("2015-01-04")), units= "days"))
photuc_data
```

```{r}
ggplotRegression(lm(average_price ~ time_dif, data = photuc_data))
```

#final phoenix/tucson graph
```{r}
photuc_data %>%  
  ggplot(aes(x= date, y= average_price))+
 geom_point(color= "palegreen4")+
geom_smooth(method= lm, se= F, color= "burlywood4")+
  labs(title = "Phoenix/Tucson Price Per Avo; Intercept = 1.2015, Slope = 0.000007", 
     x= "Date",
     y= "Average Price")+
  theme(text=element_text(size=11, family="Comic Sans MS"),
            axis.text.x = element_text(angle = 60, hjust=1))
```

```{r}
sac_data <- avo %>% 
  filter(geography == "Sacramento") %>% 
  mutate(time_dif = as.double(difftime(date, lubridate::ymd("2015-01-04")), units= "days"))
sac_data
```

```{r}
ggplotRegression(lm(average_price ~ time_dif, data = sac_data))
```

#final sac graph
```{r}
 sac_data%>% 
  ggplot(aes(x= date, y= average_price))+
  geom_point(color= "palegreen4")+
geom_smooth(method= lm, se= F, color= "burlywood4")+
  labs(title = "Sacramento Price Per Avo; Intercept = 1.5901, Slope = -0.000005", 
     x= "Date",
     y= "Average Price")+
  theme(text=element_text(size=11, family="Comic Sans MS"),
            axis.text.x = element_text(angle = 60, hjust=1))
```

##Dividing the work
tim: Coded the bar graphs about price extremities and worked on slides.
emily: general planning and defining questions, finding the answer to the questions via making scatter plots, the slides




